# search_handler.py
# (æ¤œç´¢ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†ã€Brave Search APIé€£æºã€URLãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º)

import asyncio
import re
import httpx
import discord
from typing import List, Dict, Any, Optional, Tuple, Literal

import config
import bot_constants
import llm_manager
import cache_manager # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã®ãŸã‚è¿½åŠ 
import discord_ui # Thinking message, ãƒœã‚¿ãƒ³ç”Ÿæˆç”¨
from llm_provider import ERROR_TYPE_UNKNOWN # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—å®šæ•°

# --- Brave Search API Call ---
async def call_brave_search_api(query: str) -> Optional[List[Dict[str, Any]]]:
    """Brave Search APIã‚’å‘¼ã³å‡ºã™"""
    if not config.BRAVE_SEARCH_API_KEY:
        print("Error: BRAVE_SEARCH_API_KEY is not set.")
        return None

    headers = {
        "Accept": "application/json",
        "Accept-Encoding": "gzip",
        "X-Subscription-Token": config.BRAVE_SEARCH_API_KEY,
        "User-Agent": "PlanaBot/1.0 (Discord Bot)" # é©åˆ‡ãªUser-Agent
    }
    params = {
        "q": query,
        "count": config.MAX_SEARCH_RESULTS,
        "search_filter": "web",
        # "country": "jp", # å¿…è¦ã«å¿œã˜ã¦
        # "search_lang": "ja" # å¿…è¦ã«å¿œã˜ã¦
    }

    async with httpx.AsyncClient() as client:
        try:
            print(f"Calling Brave Search API for query: '{query}'...")
            response = await client.get(config.BRAVE_SEARCH_API_URL, headers=headers, params=params, timeout=20)
            response.raise_for_status()
            data = response.json()
            results = data.get('web', {}).get('results', [])
            print(f"Brave Search API call successful. Found {len(results)} web results.")
            return results
        except httpx.HTTPStatusError as e:
            print(f"HTTP error occurred while calling Brave Search API: {e.response.status_code}")
            # print(f"Response body: {e.response.text}") # ãƒ‡ãƒãƒƒã‚°ç”¨
            return None
        except httpx.RequestError as e:
            print(f"An error occurred while requesting Brave Search API: {e}")
            return None
        except Exception as e:
            print(f"An unexpected error occurred during Brave Search API call: {e}")
            return None
        finally:
            # APIå‘¼ã³å‡ºã—ã”ã¨ã«å¿…ãšå¾…æ©Ÿ (try/except/finallyã§ä¿è¨¼)
            await asyncio.sleep(config.BRAVE_API_DELAY)


# --- URL Content Extraction ---
async def extract_text_from_url(url: str) -> Optional[str]:
    """URLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡ºã™ã‚‹ (ç°¡æ˜“ç‰ˆ)"""
    if not url or not (url.startswith("http://") or url.startswith("https://")):
        print(f"Invalid URL skipped: {url}")
        return None

    print(f"Attempting to extract text from URL: {url}")
    try:
        # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã§Content-Typeã‚’ç¢ºèª
        async with httpx.AsyncClient(timeout=10, follow_redirects=True) as client:
            try:
                 head_response = await client.head(url)
                 head_response.raise_for_status()
                 content_type = head_response.headers.get('Content-Type', '').lower()
                 # text/html, text/plain, application/json ä»¥å¤–ã‚’ã‚¹ã‚­ãƒƒãƒ—
                 if not any(ct in content_type for ct in ['text/html', 'text/plain', 'application/json']):
                     print(f"Skipping non-HTML/text/JSON content type: {content_type} for {url}")
                     return None
            except httpx.HTTPStatusError as e:
                 print(f"HEAD request failed for {url}: {e.response.status_code}")
                 return None # HEADå¤±æ•—ã¯ã‚¢ã‚¯ã‚»ã‚¹ä¸èƒ½ã¨ã¿ãªã™
            except httpx.RequestError as e:
                 print(f"HEAD request failed for {url}: {e}")
                 return None

        # GETãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—
        async with httpx.AsyncClient(timeout=30, follow_redirects=True) as client:
             response = await client.get(url)
             response.raise_for_status()
             content_type = response.headers.get('Content-Type', '').lower() # å†åº¦å–å¾—

             # Content-Typeã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²
             if 'application/json' in content_type:
                  try:
                      # JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã—ã€ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ã‚’çµåˆï¼ˆç°¡æ˜“çš„ï¼‰
                      json_data = response.json()
                      text_parts = []
                      def extract_text_from_json(data):
                          if isinstance(data, dict):
                              for key, value in data.items():
                                  if isinstance(value, str):
                                      text_parts.append(value)
                                  else:
                                      extract_text_from_json(value)
                          elif isinstance(data, list):
                              for item in data:
                                  extract_text_from_json(item)
                          elif isinstance(data, str):
                              text_parts.append(data)
                      extract_text_from_json(json_data)
                      text_content = ' '.join(text_parts).strip()
                  except Exception as json_e:
                       print(f"Failed to parse JSON or extract text from {url}: {json_e}. Falling back to raw text.")
                       text_content = response.text # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯ç”Ÿãƒ†ã‚­ã‚¹ãƒˆ
             elif 'text/html' in content_type:
                 html_content = response.text # httpxãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¨å®š
                 # HTMLã‚¿ã‚°é™¤å» (ç°¡æ˜“ç‰ˆ)
                 text_content = re.sub(r'<script.*?>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
                 text_content = re.sub(r'<style.*?>.*?</style>', '', text_content, flags=re.DOTALL | re.IGNORECASE)
                 text_content = re.sub(r'<!--.*?-->', '', text_content, flags=re.DOTALL)
                 text_content = re.sub(r'>\s*<', '> <', text_content) # ã‚¿ã‚°é–“ã®ç©ºç™½
                 text_content = re.sub(r'<.*?>', '', text_content) # å…¨ã‚¿ã‚°é™¤å»
             else: # text/plain ãªã©
                  text_content = response.text

             text_content = re.sub(r'\s+', ' ', text_content).strip() # é€£ç¶šç©ºç™½ã‚’ã¾ã¨ã‚ã‚‹

             # é•·ã•ãƒã‚§ãƒƒã‚¯ã¨åˆ‡ã‚Šè©°ã‚
             if len(text_content) > config.MAX_CONTENT_LENGTH_PER_URL:
                 text_content = text_content[:config.MAX_CONTENT_LENGTH_PER_URL] + "..."
                 print(f"Truncated content for {url} to {config.MAX_CONTENT_LENGTH_PER_URL} characters.")

             # çŸ­ã™ãã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã‚¹ã‚­ãƒƒãƒ—
             if len(text_content) < config.SEARCH_MIN_CONTENT_LENGTH:
                 print(f"Content too short ({len(text_content)} chars) for {url}. Skipping.")
                 return None

             print(f"Successfully extracted text from {url} ({len(text_content)} chars).")
             return text_content

    except httpx.HTTPStatusError as e:
        print(f"HTTP error occurred while fetching URL {url}: {e.response.status_code}")
        return None
    except httpx.RequestError as e:
        print(f"An error occurred while requesting URL {url}: {e}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred while processing URL {url}: {e}")
        return None


# --- Search Command Handler ---
async def handle_search_command(message: discord.Message, command_type: Literal['src', 'dsrc'], query_text: str):
    """!src ãŠã‚ˆã³ !dsrc ã‚³ãƒãƒ³ãƒ‰ã®å…±é€šå‡¦ç†ãƒãƒ³ãƒ‰ãƒ©"""

    if not config.BRAVE_SEARCH_API_KEY:
        await message.reply("æ¤œç´¢æ©Ÿèƒ½ã¯è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (APIã‚­ãƒ¼ä¸è¶³)ã€‚", mention_author=False)
        return

    llm_handler = llm_manager.get_current_provider()
    if not llm_handler:
        await message.reply(bot_constants.ERROR_MSG_INTERNAL + " (LLM Provider not available)", mention_author=False)
        return

    # ãƒ¢ãƒ‡ãƒ«é¸æŠã¨è¨­å®š
    if command_type == 'src':
        model_type = 'lowload'
        query_model_name = llm_manager.get_active_model_name(model_type)
        answer_model_name = query_model_name # srcã¯ä¸¡æ–¹lowload
        if not query_model_name:
            await message.reply(bot_constants.ERROR_MSG_LOWLOAD_UNAVAILABLE + f" ({llm_manager.get_current_provider_name()} ã«ä½è² è·ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“)", mention_author=False)
            return
        max_iterations = 1
    elif command_type == 'dsrc':
        model_type = 'primary'
        query_model_name = llm_manager.get_active_model_name(model_type)
        answer_model_name = query_model_name # dsrcã¯ä¸¡æ–¹primary
        if not query_model_name:
            # Primary ãŒãªã„å ´åˆã€Secondaryã§ä»£ç”¨ã‚’è©¦ã¿ã‚‹ (llm_managerå´ã§èª¿æ•´ã•ã‚Œã‚‹ã¹ãã‹ã‚‚ã—ã‚Œãªã„)
            query_model_name = llm_manager.get_active_model_name('secondary')
            answer_model_name = query_model_name
            if not query_model_name:
                await message.reply(bot_constants.ERROR_MSG_API_ERROR + f" ({llm_manager.get_current_provider_name()} ã«åˆ©ç”¨å¯èƒ½ãªPrimary/Secondaryãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“)", mention_author=False)
                return
            else:
                print(f"Warning: Primary model not found for dsrc, using secondary: {query_model_name}")
        max_iterations = config.DEEP_SEARCH_MAX_ITERATIONS
    else: # command_typeãŒäºˆæœŸã›ã¬å€¤ã®å ´åˆ
         print(f"Error: Invalid command_type '{command_type}' in handle_search_command.")
         await message.reply(bot_constants.ERROR_MSG_INTERNAL, mention_author=False)
         return

    original_question = query_text.strip()
    if not original_question:
        await message.reply(f"æ¤œç´¢ã™ã‚‹å†…å®¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚ä¾‹: `@{message.guild.me.display_name} !{command_type} ChatGPTã®æœ€æ–°æƒ…å ±`", mention_author=False)
        return

    provider_name = llm_manager.get_current_provider_name()
    print(f"[{command_type.upper()}] Search command received: '{original_question}' by {message.author.display_name} (Provider: {provider_name})")

    # æ€è€ƒä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é–‹å§‹
    await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... (æ¤œç´¢é–‹å§‹)") # ãƒ—ãƒ©ãƒŠé¢¨

    used_search_queries: List[str] = []
    all_extracted_content: Dict[str, str] = {} # URL -> text ; å…¨ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®çµæœã‚’é›†ç´„
    iteration_count = 0
    should_continue_search = True
    combined_search_results_text = "" # ã‚¹ã‚³ãƒ¼ãƒ—å¤–ã§ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«åˆæœŸåŒ–
    missing_info_from_assessment: Optional[str] = None # å‰å›ã®è©•ä¾¡ã§ä¸è¶³ã—ã¦ã„ãŸæƒ…å ±ã‚’ä¿æŒ
    final_sent_message: Optional[discord.Message] = None # é€ä¿¡ã—ãŸæœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ ¼ç´

    try:
        while should_continue_search and iteration_count < max_iterations:
            iteration_count += 1
            iteration_label = f"ç¬¬{iteration_count}å›" if command_type == 'dsrc' else ""

            # 1. æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ
            await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... ({iteration_label} æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆä¸­ using {query_model_name})")

            query_gen_prompt = ""
            # dsrcã®2å›ç›®ä»¥é™ã§ã€ã‹ã¤éå»ã®ã‚¯ã‚¨ãƒªãŒã‚ã‚‹å ´åˆ
            if command_type == 'dsrc' and iteration_count > 1 and used_search_queries:
                formatted_used_queries = "\n".join([f"- {q}" for q in used_search_queries])
                # å‰å›ã®ãƒ«ãƒ¼ãƒ—ã§å¾—ã‚‰ã‚ŒãŸä¸è¶³æƒ…å ±ã‚’åˆ©ç”¨ï¼ˆãªã‘ã‚Œã°ã€Œç‰¹ã«æŒ‡å®šãªã—ã€ï¼‰
                prompt_missing_info = missing_info_from_assessment if missing_info_from_assessment else "ç‰¹ã«æŒ‡å®šãªã—"
                query_gen_prompt = config.SEARCH_QUERY_GENERATION_PROMPT_WITH_HISTORY.format(
                    question=original_question,
                    used_queries=formatted_used_queries,
                    missing_info=prompt_missing_info # config.pyå´ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«è¿½åŠ 
                )
            else: # åˆå› ã¾ãŸã¯ src ã®å ´åˆ
                 query_gen_prompt = config.SEARCH_QUERY_GENERATION_PROMPT.format(question=original_question)

            # LLMã§ã‚¯ã‚¨ãƒªç”Ÿæˆ (srcã¯lowload, dsrcã¯primary/secondary=generate_response)
            query_response_raw: Optional[str] = None
            if command_type == 'src':
                query_response_raw = await llm_manager.generate_lowload_response(query_gen_prompt)
            elif command_type == 'dsrc':
                # generate_responseã¯ãƒ¢ãƒ‡ãƒ«åã¨å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™
                _used_model_q, response_text = await llm_manager.generate_response(content_parts=[{'text': query_gen_prompt}], chat_history=None, deep_cache_summary=None)
                query_response_raw = response_text # å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ä½¿ç”¨

            query_response_text = str(query_response_raw).strip() if query_response_raw else "" # strip() ã‚’è¿½åŠ 
            if not query_response_text or llm_manager.is_error_message(query_response_text):
                print(f"[{command_type.upper()}] Query generation failed (Iteration {iteration_count}). Response: {query_response_text}")
                await discord_ui.delete_thinking_message()
                error_msg = llm_handler.format_error_message(ERROR_TYPE_UNKNOWN, 'Query generation failed') if llm_handler else bot_constants.ERROR_MSG_GEMINI_UNKNOWN
                await message.reply(f"æ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚{error_msg}", mention_author=False)
                return

            # ã‚¯ã‚¨ãƒªã‚’ãƒ‘ãƒ¼ã‚¹ (æ”¹è¡Œã¾ãŸã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)
            queries_raw = query_response_text.replace('\n', ',')
            current_iteration_queries = [q.strip().strip('"') for q in queries_raw.split(',') if q.strip()] # ã‚¯ã‚©ãƒ¼ãƒˆã‚‚é™¤å»
            current_iteration_queries = [q for q in current_iteration_queries if q] # ç©ºã®ã‚¯ã‚¨ãƒªã‚’é™¤å»
            current_iteration_queries = current_iteration_queries[:3] # æœ€å¤§3ã¤ã«åˆ¶é™

            if not current_iteration_queries:
                if iteration_count == 1:
                     await discord_ui.delete_thinking_message()
                     await message.reply("æœ‰åŠ¹ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚", mention_author=False)
                     print(f"[{command_type.upper()}] Generated empty query list from '{query_response_text}'")
                     return
                else:
                     print(f"[{command_type.upper()}] Generated empty query list in iteration {iteration_count}. Ending search.")
                     should_continue_search = False
                     break # ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

            # æ–°ã—ã„ã‚¯ã‚¨ãƒªã®ã¿ã‚’ used_search_queries ã«è¿½åŠ 
            newly_added_queries = [q for q in current_iteration_queries if q not in used_search_queries]
            if newly_added_queries:
                 used_search_queries.extend(newly_added_queries)
                 print(f"[{command_type.upper()}] Iteration {iteration_count} queries added: {newly_added_queries}. Total used: {used_search_queries}")
            else:
                 print(f"[{command_type.upper()}] Iteration {iteration_count} generated only duplicate queries. Using existing: {current_iteration_queries}")
                 # é‡è¤‡ã‚¯ã‚¨ãƒªã§ã‚‚æ¤œç´¢ã¯è©¦ã¿ã‚‹ï¼ˆå‰å›å¤±æ•—ã—ãŸå¯èƒ½æ€§ã‚‚ã‚ã‚‹ãŸã‚ï¼‰


            # 2. Brave Search APIå‘¼ã³å‡ºã—
            current_iteration_results: List[Dict[str, Any]] = []
            for i, query in enumerate(current_iteration_queries):
                 await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... ({iteration_label} æ¤œç´¢ä¸­: `{query[:50]}...`)")
                 results = await call_brave_search_api(query)
                 if results:
                     current_iteration_results.extend(results)
                 # call_brave_search_apiå†…ã§é…å»¶å‡¦ç†æ¸ˆã¿

            if not current_iteration_results:
                await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... ({iteration_label} æ¤œç´¢çµæœãªã—)")
                if command_type == 'src' or iteration_count == 1: # åˆå›dsrcã§çµæœãªã—
                     # æ—¢å­˜ã®çµæœã‚‚ãªã„å ´åˆã¯çµ‚äº†
                     if not all_extracted_content:
                         await discord_ui.delete_thinking_message()
                         await message.reply(f"ã€Œ{original_question[:50]}...ã€ã«é–¢ã™ã‚‹æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", mention_author=False)
                         return
                     else: # æ—¢å­˜ã®çµæœã¯ã‚ã‚‹ã®ã§ã€ãã‚Œã‚’å…ƒã«å¿œç­”ç”Ÿæˆã¸
                          print(f"[{command_type.upper()}] No results in iteration {iteration_count}, but previous results exist. Ending search.")
                          should_continue_search = False
                          break
                else: # dsrc 2å›ç›®ä»¥é™ã§çµæœãªã—
                     print(f"[{command_type.upper()}] No results in iteration {iteration_count}. Ending search.")
                     should_continue_search = False
                     break # ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

            # 3. ãƒšãƒ¼ã‚¸å†…å®¹å–å¾—ã¨é›†ç´„
            unique_urls_in_iteration = list(dict.fromkeys([r['url'] for r in current_iteration_results if 'url' in r]))
            # ã¾ã å–å¾—ã—ã¦ã„ãªã„URLã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
            urls_to_fetch = [url for url in unique_urls_in_iteration if url not in all_extracted_content]
            print(f"[{command_type.upper()}] Iteration {iteration_count}: Found {len(unique_urls_in_iteration)} unique URLs, fetching {len(urls_to_fetch)} new URLs.")

            if urls_to_fetch:
                await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... ({iteration_label} ãƒšãƒ¼ã‚¸å†…å®¹å–å¾—ä¸­ {len(urls_to_fetch)}ä»¶)")
                fetch_tasks = [extract_text_from_url(url) for url in urls_to_fetch]
                extracted_contents_list = await asyncio.gather(*fetch_tasks)

                newly_extracted_count = 0
                for url, content in zip(urls_to_fetch, extracted_contents_list):
                    if content:
                        all_extracted_content[url] = content # æ–°ã—ã„å†…å®¹ã‚’è¾æ›¸ã«è¿½åŠ 
                        newly_extracted_count += 1
                print(f"[{command_type.upper()}] Iteration {iteration_count}: Successfully extracted content from {newly_extracted_count}/{len(urls_to_fetch)} new URLs.")

            # ã“ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§æœ‰åŠ¹ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå…¨ãå–å¾—ã§ããªã‹ã£ãŸå ´åˆ (æ–°è¦URLã‚‚å«ã‚€)
            # ã‹ã¤ã€æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚ãªã„å ´åˆ
            if not all_extracted_content:
                 await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... ({iteration_label} æœ‰åŠ¹ãªãƒšãƒ¼ã‚¸å†…å®¹å–å¾—ã§ããš)")
                 await discord_ui.delete_thinking_message()
                 await message.reply(f"å–å¾—ã—ãŸãƒšãƒ¼ã‚¸ã‹ã‚‰æœ‰åŠ¹ãªæƒ…å ±ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚", mention_author=False)
                 return

            # 4. dsrcã®å ´åˆã€æ¤œç´¢çµæœã®è©•ä¾¡ (é›†ç´„ã•ã‚ŒãŸå…¨çµæœã‚’ä½¿ã£ã¦è©•ä¾¡)
            missing_info_from_assessment = None # å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®è©•ä¾¡å‰ã«ãƒªã‚»ãƒƒãƒˆ
            if command_type == 'dsrc':
                # çµåˆã¨åˆ‡ã‚Šè©°ã‚ (è©•ä¾¡ç”¨)
                combined_search_results_text = "\n\n".join(
                    f"--- Content from {url} ---\n{text}\n--- End of {url} ---"
                    for url, text in all_extracted_content.items() # å…¨ä½“ã®çµæœã‚’ä½¿ã†
                )
                if len(combined_search_results_text) > config.MAX_TOTAL_SEARCH_CONTENT_LENGTH:
                    print(f"[{command_type.upper()}] Combined search content for assessment exceeds total limit. Truncating.")
                    combined_search_results_text = combined_search_results_text[:config.MAX_TOTAL_SEARCH_CONTENT_LENGTH] + "\n\n... (truncated due to length limit)"

                await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... ({iteration_label} æ¤œç´¢çµæœç¢ºèªä¸­ using {answer_model_name})")
                assessment_prompt = config.DEEP_SEARCH_ASSESSMENT_PROMPT.format(
                    question=original_question,
                    search_results_text=combined_search_results_text
                )
                # generate_responseã‚’ä½¿ç”¨
                _used_model_a, assessment_response_raw = await llm_manager.generate_response(
                    content_parts=[{'text': assessment_prompt}], chat_history=None, deep_cache_summary=None
                )
                assessment_response_text = str(assessment_response_raw).strip() if assessment_response_raw else "" # strip() ã‚’è¿½åŠ 

                if assessment_response_text and not llm_manager.is_error_message(assessment_response_text):
                    print(f"[{command_type.upper()}] Iteration {iteration_count} assessment: {assessment_response_text}")
                    if assessment_response_text.upper() == 'COMPLETE':
                        print(f"[{command_type.upper()}] Assessment: COMPLETE. Ending search loop.")
                        should_continue_search = False
                    elif assessment_response_text.upper().startswith('INCOMPLETE:'):
                        # ã“ã“ã§ä¸è¶³æƒ…å ±ã‚’æŠ½å‡ºã—ã€æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã«ä¿æŒ
                        missing_info_from_assessment = assessment_response_text.split(':', 1)[1].strip() if ':' in assessment_response_text else "è©³ç´°ä¸æ˜"
                        print(f"[{command_type.upper()}] Assessment: INCOMPLETE. Missing: {missing_info_from_assessment[:100]}...")
                        if iteration_count < max_iterations:
                             await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... ({iteration_label} è¿½åŠ æƒ…å ±æ¢ç´¢æº–å‚™ä¸­)")
                             await asyncio.sleep(1) # æ¬¡ã®æ¤œç´¢ã¾ã§å°‘ã—å¾…ã¤
                        else:
                            print(f"[{command_type.upper()}] Max iterations reached ({max_iterations}). Ending search loop.")
                            should_continue_search = False
                    else:
                         # äºˆæœŸã›ã¬å½¢å¼ã§ã‚‚ã€ã¨ã‚Šã‚ãˆãšç¶šè¡Œã—ã¦ã¿ã‚‹ï¼ˆå†…å®¹ãŒæ¬¡ã®ã‚¯ã‚¨ãƒªç”Ÿæˆã®ãƒ’ãƒ³ãƒˆã«ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ï¼‰
                         print(f"[{command_type.upper()}] Unexpected assessment format: '{assessment_response_text}'. Continuing search if possible.")
                         if iteration_count >= max_iterations:
                             print(f"[{command_type.upper()}] Max iterations reached after unexpected assessment. Ending search loop.")
                             should_continue_search = False
                else:
                    print(f"[{command_type.upper()}] Assessment failed (Iteration {iteration_count}). Response: {assessment_response_text}. Ending search loop.")
                    should_continue_search = False # è©•ä¾¡å¤±æ•—æ™‚ã¯ãƒ«ãƒ¼ãƒ—çµ‚äº†

            elif command_type == 'src':
                should_continue_search = False # src ã¯1å›ã§çµ‚äº†

        # --- ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œ ---

        # æœ€çµ‚å¿œç­”ã®ãŸã‚ã« combined_search_results_text ã‚’å†ç”Ÿæˆ (æœ€æ–°ã® all_extracted_content ã‚’ä½¿ç”¨)
        combined_search_results_text = "\n\n".join(
            f"--- Content from {url} ---\n{text}\n--- End of {url} ---"
            for url, text in all_extracted_content.items()
        )
        if len(combined_search_results_text) > config.MAX_TOTAL_SEARCH_CONTENT_LENGTH:
            print(f"[{command_type.upper()}] Final combined search content exceeds total limit. Truncating.")
            combined_search_results_text = combined_search_results_text[:config.MAX_TOTAL_SEARCH_CONTENT_LENGTH] + "\n\n... (truncated due to length limit)"


        if not combined_search_results_text: # ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ãŸçµæœã€æœ‰åŠ¹ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå…¨ããªã„å ´åˆ
             await discord_ui.delete_thinking_message()
             await message.reply("æ¤œç´¢ã«ã‚ˆã£ã¦è³ªå•ã«å›ç­”ã™ã‚‹ãŸã‚ã®æœ‰åŠ¹ãªæƒ…å ±ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚", mention_author=False)
             return

        await discord_ui.update_thinking_message(message.channel, f"â€¦è€ƒãˆä¸­... (æœ€çµ‚å¿œç­”ç”Ÿæˆä¸­ using {answer_model_name})")

        # æœ€çµ‚å¿œç­”ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ãƒšãƒ«ã‚½ãƒŠåæ˜ ã€ã‚½ãƒ¼ã‚¹æŒ‡ç¤ºè¾¼ã¿)
        answer_prompt = config.SEARCH_ANSWER_PROMPT.format(
            question=original_question,
            search_results_text=combined_search_results_text
        )

        # æœ€çµ‚å¿œç­”ç”Ÿæˆ
        final_response_raw: Optional[str] = None
        used_model_name_for_header = answer_model_name or "N/A"

        if command_type == 'src':
             final_response_raw = await llm_manager.generate_lowload_response(answer_prompt)
        elif command_type == 'dsrc':
             _used_model_f, response_text = await llm_manager.generate_response(
                 content_parts=[{'text': answer_prompt}], chat_history=None, deep_cache_summary=None
             )
             final_response_raw = response_text

        final_response_text = str(final_response_raw).strip() if final_response_raw else "" # strip() ã‚’è¿½åŠ 

        if not final_response_text or llm_manager.is_error_message(final_response_text):
            print(f"[{command_type.upper()}] Final answer generation failed. Response: {final_response_text}")
            await discord_ui.delete_thinking_message()
            error_msg = llm_handler.format_error_message(ERROR_TYPE_UNKNOWN, 'Answer generation failed') if llm_handler else bot_constants.ERROR_MSG_GEMINI_UNKNOWN
            await message.reply(f"å¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚{error_msg}", mention_author=False)
            return

        # æœ€çµ‚å¿œç­”ã‚’Discordã«é€ä¿¡
        await discord_ui.delete_thinking_message()
        response_header = f"(ğŸ” **{command_type.upper()} Search Result** using {used_model_name_for_header} ğŸ”)\n\n"
        full_response = response_header + final_response_text

        # --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æŒ‡ç¤ºã—ãŸã‚½ãƒ¼ã‚¹ãƒªã‚¹ãƒˆãŒLLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œãªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ---
        source_header = "**å‚ç…§ã‚½ãƒ¼ã‚¹:**"
        if source_header not in full_response and all_extracted_content:
             print(f"[{command_type.upper()}] LLM did not include sources. Appending manually.")
             source_list = "\n".join([f"- <{url}>" for url in all_extracted_content.keys()])
             full_response += f"\n\n{source_header}\n{source_list}"


        # å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ†å‰²é€ä¿¡
        if len(full_response) > 2000:
            print(f"[{command_type.upper()}] Final response length ({len(full_response)}) exceeds 2000. Sending in chunks.")
            response_chunks = [full_response[i:i+1990] for i in range(0, len(full_response), 1990)]
            first_chunk = True
            try:
                for chunk in response_chunks:
                    if first_chunk:
                        # æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯é€ä¿¡æ™‚ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
                        final_sent_message = await message.reply(chunk, mention_author=False)
                        first_chunk = False
                    else:
                        await message.channel.send(chunk)
                    await asyncio.sleep(0.5)
            except discord.HTTPException as e:
                 print(f"[{command_type.upper()}] Error sending chunked final response: {e}")
                 if not final_sent_message: # æœ€åˆã®é€ä¿¡ã§å¤±æ•—ã—ãŸå ´åˆ
                      await message.channel.send(bot_constants.ERROR_MSG_INTERNAL + " (å¿œç­”é€ä¿¡å¤±æ•—)")
        else:
            try:
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
                final_sent_message = await message.reply(full_response, mention_author=False)
            except discord.HTTPException as e:
                 print(f"[{command_type.upper()}] Error sending final response: {e}")
                 await message.channel.send(bot_constants.ERROR_MSG_INTERNAL + " (å¿œç­”é€ä¿¡å¤±æ•—)")


        # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°ã¨è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ã®è¿½åŠ  (å¿œç­”æˆåŠŸå¾Œ) ---
        if final_sent_message and final_response_text and not llm_manager.is_error_message(final_response_text):
            # 1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
            try:
                print(f"[{command_type.upper()}] Updating cache for channel {message.channel.id}...")
                # mentionã‚’é™¤å»ã—ãŸå®Œå…¨ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ (ã‚³ãƒãƒ³ãƒ‰å«ã‚€)
                mention_strings = [f'<@!{message.guild.me.id}>', f'<@{message.guild.me.id}>']
                user_input_text = message.content # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’å–å¾—
                for mention in mention_strings:
                    user_input_text = user_input_text.replace(mention, '').strip()

                chat_history = await cache_manager.load_cache(message.channel.id)
                user_entry = {'role': 'user', 'parts': [{'text': user_input_text}]} # æ¤œç´¢ã‚³ãƒãƒ³ãƒ‰ã¨ã‚¯ã‚¨ãƒª
                model_entry = {'role': 'model', 'parts': [{'text': final_response_text}]} # LLMã®å¿œç­”
                await cache_manager.save_cache(message.channel.id, chat_history + [user_entry, model_entry])
                print(f"[{command_type.upper()}] Cache updated.")
            except Exception as cache_e:
                print(f"[{command_type.upper()}] Error updating cache: {cache_e}")

            # 2. è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ç”Ÿæˆ
            try:
                 # éåŒæœŸã§ãƒœã‚¿ãƒ³ç”Ÿæˆãƒ»è¿½åŠ ã‚’å®Ÿè¡Œ
                 print(f"[{command_type.upper()}] Generating follow-up buttons...")
                 asyncio.create_task(discord_ui.generate_and_add_followup_buttons(final_sent_message, message.channel.id))
            except Exception as btn_e:
                 print(f"[{command_type.upper()}] Error scheduling follow-up button generation: {btn_e}")


    except Exception as e:
        print(f"[{command_type.upper()}] An unexpected error occurred during search process: {e}")
        import traceback
        traceback.print_exc()
        await discord_ui.delete_thinking_message()
        # message.reply ã®ä»£ã‚ã‚Šã« message.channel.send ã‚’ä½¿ã† (replyã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ä¾å­˜ã™ã‚‹å¯èƒ½æ€§)
        await message.channel.send(bot_constants.ERROR_MSG_INTERNAL + f" (æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}...)")