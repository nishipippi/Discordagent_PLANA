# bot.py
# (ãƒ¡ã‚¤ãƒ³ã®ãƒœãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ« - APIå‘¼ã³å‡ºã—ã‚’æŠ½è±¡åŒ–)

import discord
import os
import asyncio
import re
import json
import aiofiles
import mimetypes
import base64
from typing import List, Dict, Any, Optional, Tuple
from dotenv import load_dotenv

# --- ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨å®šæ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from llm_provider import LLMProvider # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
from gemini_provider import GeminiProvider # Geminiå®Ÿè£…
from openai_compatible_provider import OpenAICompatibleProvider # OpenAIäº’æ›å®Ÿè£… (Mistralå«ã‚€)
import bot_constants # å®šæ•°ãƒ•ã‚¡ã‚¤ãƒ«

# --- è¨­å®šé …ç›® ---
# 0. ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
try:
    load_dotenv()
    print(".env ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸã€‚")
except Exception as e:
    print(f"è­¦å‘Š: .env ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

LLM_PROVIDER_NAME = os.getenv('LLM_PROVIDER', 'GEMINI').upper()
DISCORD_TOKEN = os.getenv('DISCORD_TOKEN')

GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')
MISTRAL_API_BASE_URL = os.getenv('MISTRAL_API_BASE_URL', 'https://api.mistral.ai/v1')

MODEL_CONFIG: Dict[str, str] = {}
API_KEY_FOR_PROVIDER: Optional[str] = None
API_BASE_URL_FOR_PROVIDER: Optional[str] = None

if LLM_PROVIDER_NAME == 'GEMINI':
    MODEL_CONFIG['primary'] = os.getenv('GEMINI_PRIMARY_MODEL', 'gemini-1.5-pro-latest')
    MODEL_CONFIG['secondary'] = os.getenv('GEMINI_SECONDARY_MODEL', 'gemini-1.5-flash-latest')
    MODEL_CONFIG['lowload'] = os.getenv('GEMINI_LOWLOAD_MODEL', 'gemini-1.5-flash-latest')
    API_KEY_FOR_PROVIDER = GEMINI_API_KEY
    API_BASE_URL_FOR_PROVIDER = None

elif LLM_PROVIDER_NAME == 'MISTRAL':
    MODEL_CONFIG['primary'] = os.getenv('MISTRAL_PRIMARY_MODEL', 'pixtral-large-latest')
    MODEL_CONFIG['secondary'] = os.getenv('MISTRAL_SECONDARY_MODEL', MODEL_CONFIG.get('primary', 'mistral-large-latest'))
    MODEL_CONFIG['lowload'] = os.getenv('MISTRAL_LOWLOAD_MODEL', 'mistral-small-latest')
    API_KEY_FOR_PROVIDER = MISTRAL_API_KEY
    API_BASE_URL_FOR_PROVIDER = MISTRAL_API_BASE_URL

else:
    print(f"Error: Unknown LLM_PROVIDER '{LLM_PROVIDER_NAME}' specified in .env. Please use 'GEMINI' or 'MISTRAL'.")
    print("Attempting to initialize with GEMINI provider settings as a fallback.")
    LLM_PROVIDER_NAME = 'GEMINI'
    MODEL_CONFIG['primary'] = os.getenv('GEMINI_PRIMARY_MODEL', 'gemini-1.5-pro-latest')
    MODEL_CONFIG['secondary'] = os.getenv('GEMINI_SECONDARY_MODEL', 'gemini-1.5-flash-latest')
    MODEL_CONFIG['lowload'] = os.getenv('GEMINI_LOWLOAD_MODEL', 'gemini-1.5-flash-latest')
    API_KEY_FOR_PROVIDER = GEMINI_API_KEY
    API_BASE_URL_FOR_PROVIDER = None


# 2. ãƒšãƒ«ã‚½ãƒŠè¨­å®š
PERSONA_TEMPLATE = bot_constants.PERSONA_TEMPLATE
PERSONA_INSTRUCTION = ""

# 3. ä¼šè©±ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
CACHE_DIR = "cache"
CACHE_LIMIT = 10

# 4. Deep Cache è¨­å®š
DEEP_CACHE_DIR = "deep_cache"
DEEP_CACHE_EXTRACT_PROMPT = """
ä»¥ä¸‹ã®éå»ã®ä¼šè©±å±¥æ­´ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã€ç¹°ã‚Šè¿”ã—è©±é¡Œã«ãªã‚‹ãƒˆãƒ”ãƒƒã‚¯ã€é‡è¦ãªè¨­å®šã‚„æ±ºå®šäº‹é …ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢ã™ã‚‹ç‰¹ç­†ã™ã¹ãæƒ…å ±ãªã©ã‚’æŠ½å‡ºã—ã€ç®‡æ¡æ›¸ãã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚å€‹äººã‚’ç‰¹å®šã—ã™ãã‚‹æƒ…å ±ã‚„ä¸€æ™‚çš„ãªæŒ¨æ‹¶ãªã©ã¯é™¤å¤–ã—ã¦ãã ã•ã„ã€‚

--- éå»ã®ä¼šè©±å±¥æ­´ ---
{history_text}
--- ã“ã“ã¾ã§ ---

æŠ½å‡ºçµæœï¼ˆç®‡æ¡æ›¸ãï¼‰:
"""
DEEP_CACHE_MERGE_PROMPT = """
ä»¥ä¸‹ã®äºŒã¤ã®ç®‡æ¡æ›¸ããƒªã‚¹ãƒˆï¼ˆæ—¢å­˜ã®é•·æœŸè¨˜æ†¶ã¨ã€æ–°ã—ãæŠ½å‡ºã•ã‚ŒãŸæƒ…å ±ï¼‰ã‚’çµ±åˆã—ã€é‡è¤‡ã™ã‚‹å†…å®¹ã‚’è³¢ãå‰Šé™¤ãƒ»æ•´ç†ã—ã¦ã€ä¸€ã¤ã®ç°¡æ½”ãªç®‡æ¡æ›¸ããƒªã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã€é‡è¦ãªæ±ºå®šäº‹é …ã€ç¹°ã‚Šè¿”ã—è©±é¡Œã«ãªã‚‹ãƒˆãƒ”ãƒƒã‚¯ãªã©ã‚’ä¸­å¿ƒã«æ®‹ã—ã€æƒ…å ±ã®é®®åº¦ã‚‚è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚ãƒªã‚¹ãƒˆãŒé•·ããªã‚Šã™ãã‚‹å ´åˆã¯ã€é‡è¦åº¦ã®ä½ã„ã‚‚ã®ã‹ã‚‰çœç•¥ã—ã¦ãã ã•ã„ã€‚

--- æ—¢å­˜ã®é•·æœŸè¨˜æ†¶ ---
{existing_summary}
--- ã“ã“ã¾ã§ ---

--- æ–°ã—ãæŠ½å‡ºã•ã‚ŒãŸæƒ…å ± ---
{new_summary}
--- ã“ã“ã¾ã§ ---

çµ±åˆãƒ»æ•´ç†å¾Œã®é•·æœŸè¨˜æ†¶ï¼ˆç®‡æ¡æ›¸ããƒªã‚¹ãƒˆï¼‰:
"""
DEEP_CACHE_SUMMARIZE_PROMPT = """
ä»¥ä¸‹ã®é•·æœŸè¨˜æ†¶ãƒªã‚¹ãƒˆã®å†…å®¹ã‚’ç²¾æŸ»ã—ã€é‡è¤‡ã™ã‚‹é …ç›®ã‚’å‰Šé™¤ãƒ»çµ±åˆã—ã€ã‚ˆã‚Šç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„å½¢ã«æ•´ç†ã—ã¦ãã ã•ã„ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã€é‡è¦ãªæ±ºå®šäº‹é …ã€ç¹°ã‚Šè¿”ã—è©±é¡Œã«ãªã‚‹ãƒˆãƒ”ãƒƒã‚¯ãªã©ã‚’ä¸­å¿ƒã«æ®‹ã—ã€æƒ…å ±ã®é®®åº¦ã‚‚è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚ãƒªã‚¹ãƒˆãŒé•·ããªã‚Šã™ãã‚‹å ´åˆã¯ã€é‡è¦åº¦ã®ä½ã„ã‚‚ã®ã‹ã‚‰çœç•¥ã—ã¦ãã ã•ã„ã€‚

--- æ•´ç†å¯¾è±¡ã®é•·æœŸè¨˜æ†¶ãƒªã‚¹ãƒˆ ---
{summary_to_clean}
--- ã“ã“ã¾ã§ ---

æ•´ç†å¾Œã®é•·æœŸè¨˜æ†¶ï¼ˆç®‡æ¡æ›¸ããƒªã‚¹ãƒˆï¼‰:
"""

# 5. Discordãƒãƒ£ãƒ³ãƒãƒ«å±¥æ­´å–å¾—ä»¶æ•°
HISTORY_LIMIT = 10

# 6. ãƒœã‚¿ãƒ³ç”Ÿæˆç”¨è¨­å®š
FOLLOW_UP_PROMPT = """
ä»¥ä¸‹ã®ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¬¡ã«é–¢å¿ƒã‚’æŒã¡ãã†ãªè³ªå•ã‚„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æœ€å¤§3ã¤ææ¡ˆã—ã¦ãã ã•ã„ã€‚ãã‚Œãã‚Œã®ææ¡ˆã¯ã€Discordã®ãƒœã‚¿ãƒ³ãƒ©ãƒ™ãƒ«ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã‚‹15æ–‡å­—ç¨‹åº¦ã®çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã«ã—ã¦ãã ã•ã„ã€‚ææ¡ˆãŒä¸è¦ãªå ´åˆã‚„ã€é©åˆ‡ãªææ¡ˆãŒæ€ã„ã¤ã‹ãªã„å ´åˆã¯ã€Œææ¡ˆãªã—ã€ã¨ã ã‘å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ææ¡ˆã¯ç°¡æ½”ã‹ã¤å…·ä½“çš„ã«ã—ã¦ãã ã•ã„ã€‚

--- ç›´è¿‘ã®ä¼šè©±å±¥æ­´ ---
{recent_history_text}
--- ã“ã“ã¾ã§ ---

ææ¡ˆï¼ˆå„è¡Œã«1ã¤ãšã¤è¨˜è¿°ã€æœ€å¤§3è¡Œï¼‰:
"""
MAX_FOLLOW_UP_BUTTONS = 3

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
llm_handler: Optional[LLMProvider] = None
discord_client_id = "Unknown"

# --- åˆæœŸåŒ–å‡¦ç† ---
async def initialize_llm_provider() -> bool:
    """è¨­å®šã«åŸºã¥ã„ã¦LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹"""
    global llm_handler, PERSONA_INSTRUCTION
    if not discord_client_id or discord_client_id == "Unknown":
        print("è­¦å‘Š: Discord Client ID ãŒæœªè¨­å®šã§ã™ã€‚PERSONA_INSTRUCTION ãŒä¸å®Œå…¨ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    PERSONA_INSTRUCTION = PERSONA_TEMPLATE.format(client_id=discord_client_id)

    try:
        if LLM_PROVIDER_NAME == 'GEMINI':
            llm_handler = GeminiProvider()
            if not API_KEY_FOR_PROVIDER:
                 print("CRITICAL: API Key (GEMINI_API_KEY) not found in .env.")
                 llm_handler = None
                 return False

        elif LLM_PROVIDER_NAME == 'MISTRAL':
            llm_handler = OpenAICompatibleProvider()
            if not API_KEY_FOR_PROVIDER:
                 print("CRITICAL: API Key (MISTRAL_API_KEY) not found in .env.")
                 llm_handler = None
                 return False
            if not API_BASE_URL_FOR_PROVIDER:
                 print("CRITICAL: API Base URL (MISTRAL_API_BASE_URL) not found in .env.")
                 llm_handler = None
                 return False

        else:
            print(f"CRITICAL: Invalid LLM_PROVIDER '{LLM_PROVIDER_NAME}'.")
            llm_handler = None
            return False

        print(f"Initializing {LLM_PROVIDER_NAME} Provider...")
        initialized = await llm_handler.initialize(
            api_key=API_KEY_FOR_PROVIDER,
            model_config=MODEL_CONFIG,
            system_prompt=PERSONA_INSTRUCTION,
            base_url=API_BASE_URL_FOR_PROVIDER
        )

        if not initialized:
            print(f"CRITICAL: {LLM_PROVIDER_NAME} provider's initialize method returned False.")
            llm_handler = None
            return False

        print(f"{LLM_PROVIDER_NAME} Provider initialized successfully.")
        return True

    except Exception as e:
        print(f"CRITICAL: Exception caught during LLM Provider initialization setup: {e}")
        llm_handler = None
        return False


# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ & Deep Cache ç®¡ç† ---
# (å¤‰æ›´ãªã—)
async def load_cache(channel_id: int) -> List[Dict[str, Any]]:
    cache_file = os.path.join(CACHE_DIR, f"{channel_id}.json")
    if not os.path.exists(cache_file): return []
    try:
        async with aiofiles.open(cache_file, mode='r', encoding='utf-8') as f:
            content = await f.read()
            if not content: return []
            data = json.loads(content)
            for entry in data:
                decoded_parts = []
                if 'parts' not in entry: continue
                for part in entry['parts']:
                    decoded_part = {}
                    if 'text' in part:
                        decoded_part['text'] = part['text']
                    elif 'inline_data' in part and isinstance(part.get('inline_data', {}).get('data'), str):
                        try:
                            decoded_part['inline_data'] = {
                                'mime_type': part['inline_data']['mime_type'],
                                'data': base64.b64decode(part['inline_data']['data'])
                            }
                        except Exception as e:
                            print(f"è­¦å‘Š: ã‚­ãƒ£ãƒƒã‚·ãƒ¥Base64ãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—: {e}, ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚ Part: {part}")
                            continue
                    else: pass
                    if decoded_part: decoded_parts.append(decoded_part)
                entry['parts'] = decoded_parts
            return data
    except json.JSONDecodeError:
        print(f"è­¦å‘Š: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ {cache_file} ãŒå£Šã‚Œã¦ã„ã¾ã™ã€‚ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚")
        await save_cache(channel_id, [])
        return []
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ {cache_file} èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return []

async def save_cache(channel_id: int, history: List[Dict[str, Any]]):
    if not os.path.exists(CACHE_DIR):
        try: os.makedirs(CACHE_DIR)
        except Exception as e: print(f"ã‚¨ãƒ©ãƒ¼: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {CACHE_DIR} ä½œæˆå¤±æ•—: {e}"); return

    cache_file = os.path.join(CACHE_DIR, f"{channel_id}.json")
    try:
        num_entries_to_keep = CACHE_LIMIT * 2
        history_to_save = history
        if len(history) > num_entries_to_keep:
            history_for_deep_cache = history[:-num_entries_to_keep]
            history_to_save = history[-num_entries_to_keep:]
            print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¸Šé™è¶…éã€‚å¤ã„å±¥æ­´ ({len(history_for_deep_cache)}ä»¶) ã‚’Deep Cacheæ›´æ–°ã«ä½¿ç”¨ã—ã¾ã™ã€‚")
            asyncio.create_task(update_deep_cache(channel_id, history_for_deep_cache))

        encoded_history = []
        for entry in history_to_save:
            encoded_parts = []
            if 'parts' not in entry: continue
            for part in entry['parts']:
                encoded_part = {}
                if 'text' in part:
                    encoded_part['text'] = part['text']
                elif 'inline_data' in part and isinstance(part['inline_data'].get('data'), bytes):
                    try:
                        encoded_part['inline_data'] = {
                            'mime_type': part['inline_data']['mime_type'],
                            'data': base64.b64encode(part['inline_data']['data']).decode('utf-8')
                        }
                    except Exception as e:
                         print(f"è­¦å‘Š: ã‚­ãƒ£ãƒƒã‚·ãƒ¥Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¤±æ•—: {e}, ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚ Part: {part}")
                         continue
                else: pass
                if encoded_part: encoded_parts.append(encoded_part)
            if encoded_parts: encoded_history.append({'role': entry['role'], 'parts': encoded_parts})

        async with aiofiles.open(cache_file, mode='w', encoding='utf-8') as f:
            await f.write(json.dumps(encoded_history, ensure_ascii=False, indent=2))
        # print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å®Œäº† (Channel: {channel_id}). {bot_constants.BIO_RECORD_MSG}")

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ {cache_file} æ›¸ãè¾¼ã¿å¤±æ•—: {e}")

async def load_deep_cache(channel_id: int) -> Optional[str]:
    deep_cache_file = os.path.join(DEEP_CACHE_DIR, f"{channel_id}.json")
    if not os.path.exists(deep_cache_file): return None
    try:
        async with aiofiles.open(deep_cache_file, mode='r', encoding='utf-8') as f:
            content = await f.read()
            if not content: return None
            data = json.loads(content)
            return data.get("summary")
    except json.JSONDecodeError:
        print(f"è­¦å‘Š: Deep Cache {deep_cache_file} ãŒå£Šã‚Œã¦ã„ã¾ã™ã€‚ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚")
        await save_deep_cache(channel_id, None)
        return None
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: Deep Cache {deep_cache_file} èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return None

async def save_deep_cache(channel_id: int, summary: Optional[str]):
    if not os.path.exists(DEEP_CACHE_DIR):
        try: os.makedirs(DEEP_CACHE_DIR)
        except Exception as e: print(f"ã‚¨ãƒ©ãƒ¼: Deep Cacheãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {DEEP_CACHE_DIR} ä½œæˆå¤±æ•—: {e}"); return

    deep_cache_file = os.path.join(DEEP_CACHE_DIR, f"{channel_id}.json")
    try:
        data_to_save = {"summary": summary if summary else ""}
        async with aiofiles.open(deep_cache_file, mode='w', encoding='utf-8') as f:
            await f.write(json.dumps(data_to_save, ensure_ascii=False, indent=2))
        # print(f"Deep Cache ä¿å­˜å®Œäº† (Channel: {channel_id}). {bot_constants.BIO_RECORD_MSG}")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: Deep Cache {deep_cache_file} æ›¸ãè¾¼ã¿å¤±æ•—: {e}")

def _format_history_for_prompt(history: List[Dict[str, Any]]) -> str:
    formatted_lines = []
    for entry in history:
        role = entry.get('role', 'unknown').capitalize()
        text_parts = []
        for part in entry.get('parts', []):
            if 'text' in part: text_parts.append(part['text'])
            elif 'inline_data' in part: text_parts.append(f"[{part['inline_data'].get('mime_type', 'ãƒ•ã‚¡ã‚¤ãƒ«')} æ·»ä»˜]")
        content = " ".join(text_parts).strip()
        if content:
            max_len = 500
            if len(content) > max_len: content = content[:max_len] + "..."
            formatted_lines.append(f"{role}: {content}")
    return "\n".join(formatted_lines)

# --- Deep Cache æ›´æ–°ãƒ»æ•´ç†é–¢æ•° (LLMå‘¼ã³å‡ºã—ã‚’æŠ½è±¡åŒ–) ---
async def update_deep_cache(channel_id: int, old_history: List[Dict[str, Any]]):
    """Deep Cacheã‚’æ›´æ–°ã™ã‚‹"""
    if not llm_handler: return # LLMæœªåˆæœŸåŒ–

    print(f"Deep Cacheæ›´æ–°é–‹å§‹ (Channel: {channel_id})...")
    history_text = _format_history_for_prompt(old_history)
    if not history_text.strip():
        print(f"Deep Cacheæ›´æ–°ã‚¹ã‚­ãƒƒãƒ— (Channel: {channel_id}): æŠ½å‡ºå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆãªã—ã€‚")
        return

    extract_prompt = DEEP_CACHE_EXTRACT_PROMPT.format(history_text=history_text)
    extracted_summary = await llm_handler.generate_lowload_response(extract_prompt)

    if not extracted_summary or not extracted_summary.strip():
        print(f"Deep Cacheæ›´æ–°: æ–°æƒ…å ±æŠ½å‡ºå¤±æ•—/ç©º (Channel: {channel_id})ã€‚æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¶­æŒã€‚")
        return
    print(f"Deep Cache: æ–°æƒ…å ±æŠ½å‡º:\n{extracted_summary[:300]}...")

    existing_summary = await load_deep_cache(channel_id)
    final_summary = extracted_summary

    if existing_summary and existing_summary.strip():
        print("Deep Cache: æ—¢å­˜æƒ…å ±ã¨æ–°æƒ…å ±ã‚’çµ±åˆ...")
        merge_prompt = DEEP_CACHE_MERGE_PROMPT.format(
            existing_summary=existing_summary, new_summary=extracted_summary
        )
        merged_summary = await llm_handler.generate_lowload_response(merge_prompt)
        if merged_summary and merged_summary.strip():
            final_summary = merged_summary
            print(f"Deep Cache: çµ±åˆå¾Œæƒ…å ±ç”Ÿæˆ:\n{final_summary[:300]}...")
        else:
            print("Deep Cacheæ›´æ–°è­¦å‘Š: çµ±åˆå¤±æ•—ã€‚æ–°æƒ…å ±ã®ã¿ä½¿ç”¨ã€‚")
    else:
        print("Deep Cache: æ—¢å­˜æƒ…å ±ãªã—ã€‚æŠ½å‡ºæƒ…å ±ã‚’ãã®ã¾ã¾ä½¿ç”¨ã€‚")

    await save_deep_cache(channel_id, final_summary)
    print(f"Deep Cacheæ›´æ–°å®Œäº† (Channel: {channel_id})")

async def summarize_deep_cache(channel_id: int) -> tuple[bool, str]:
    """Deep Cacheã‚’æ•´ç†ãƒ»è¦ç´„ã™ã‚‹"""
    if not llm_handler:
        return False, bot_constants.ERROR_MSG_LOWLOAD_UNAVAILABLE

    print(f"Deep Cache æ•´ç†é–‹å§‹ (!csum, Channel: {channel_id})...")
    existing_summary = await load_deep_cache(channel_id)

    if not existing_summary or not existing_summary.strip():
        print("Deep Cache æ•´ç†ã‚¹ã‚­ãƒƒãƒ—: å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚")
        return False, "é•·æœŸè¨˜æ†¶(Deep Cache)ã«ã¯ç¾åœ¨ä½•ã‚‚è¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

    summarize_prompt = DEEP_CACHE_SUMMARIZE_PROMPT.format(summary_to_clean=existing_summary)
    cleaned_summary = await llm_handler.generate_lowload_response(summarize_prompt)

    if not cleaned_summary or not cleaned_summary.strip():
        print("Deep Cache æ•´ç†å¤±æ•—: ä½è² è·ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æœ‰åŠ¹ãªæ•´ç†çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        return False, bot_constants.ERROR_MSG_DEEP_CACHE_FAIL + " æ•´ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

    await save_deep_cache(channel_id, cleaned_summary)
    print(f"Deep Cache æ•´ç†å®Œäº† (Channel: {channel_id})ã€‚")
    return True, f"é•·æœŸè¨˜æ†¶ã®æ•´ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚å†…å®¹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n```\n{cleaned_summary}\n```"


# --- ãƒœã‚¿ãƒ³ç”Ÿæˆãƒ»å‡¦ç†ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (LLMå‘¼ã³å‡ºã—ã‚’æŠ½è±¡åŒ–) ---
async def generate_and_add_followup_buttons(message_to_edit: discord.Message, channel_id: int):
    """è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ã‚’ç”Ÿæˆã—ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ ã™ã‚‹"""
    # ä½è² è·ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’ llm_handler.get_model_name ã§ç¢ºèª
    if not llm_handler or not llm_handler.get_model_name('lowload'):
        print("è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ç”Ÿæˆã‚¹ã‚­ãƒƒãƒ—: LLMãƒãƒ³ãƒ‰ãƒ©ãƒ¼æœªåˆæœŸåŒ–ã¾ãŸã¯ä½è² è·ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ä¸å¯ã€‚")
        return

    print(f"è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ç”Ÿæˆè©¦è¡Œ (Channel: {channel_id})...")
    chat_history = await load_cache(channel_id)
    if not chat_history:
        print("è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ç”Ÿæˆã‚¹ã‚­ãƒƒãƒ—: ã‚­ãƒ£ãƒƒã‚·ãƒ¥å±¥æ­´ãªã—ã€‚")
        return

    recent_history = chat_history[-2:] if len(chat_history) >= 2 else chat_history[-1:]
    recent_history_text = _format_history_for_prompt(recent_history)

    if not recent_history_text.strip():
        print("è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ç”Ÿæˆã‚¹ã‚­ãƒƒãƒ—: å±¥æ­´ãƒ†ã‚­ã‚¹ãƒˆç©ºã€‚")
        return

    button_prompt = FOLLOW_UP_PROMPT.format(recent_history_text=recent_history_text)
    follow_up_suggestions_raw = await llm_handler.generate_lowload_response(button_prompt)

    if follow_up_suggestions_raw and "ææ¡ˆãªã—" not in follow_up_suggestions_raw:
        follow_up_prompts = [line.strip() for line in follow_up_suggestions_raw.split('\n') if line.strip()][:MAX_FOLLOW_UP_BUTTONS]
        if follow_up_prompts:
             print(f"ç”Ÿæˆã•ã‚ŒãŸè¿½è·¡è³ªå•å€™è£œ: {follow_up_prompts}")
             try:
                 view = FollowUpView(original_message=message_to_edit, follow_up_prompts=follow_up_prompts)
                 await message_to_edit.edit(view=view)
                 print("è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ ã—ã¾ã—ãŸã€‚")
             except discord.NotFound: print("è­¦å‘Š: ãƒœã‚¿ãƒ³è¿½åŠ å¯¾è±¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
             except discord.Forbidden: print(f"è­¦å‘Š: {bot_constants.ERROR_MSG_PERMISSION_DENIED} (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç·¨é›†)")
             except Exception as e: print(f"ã‚¨ãƒ©ãƒ¼: è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¸ã®è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        else: print("ä½è² è·ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æœ‰åŠ¹ãªè¿½è·¡è³ªå•å€™è£œãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    else: print("ä½è² è·ãƒ¢ãƒ‡ãƒ«ãŒè¿½è·¡è³ªå•ã®ææ¡ˆã‚’ç”Ÿæˆã—ã¾ã›ã‚“ã§ã—ãŸã€‚")


# --- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ (ãƒœã‚¿ãƒ³View) ---
class FollowUpView(discord.ui.View):
    def __init__(self, original_message: discord.Message, follow_up_prompts: List[str], timeout: float = 180.0):
        super().__init__(timeout=timeout)
        self.original_message = original_message
        self.follow_up_prompts = follow_up_prompts
        for i, prompt_text in enumerate(follow_up_prompts):
            button_label = prompt_text[:80]
            button = discord.ui.Button(label=button_label, style=discord.ButtonStyle.secondary, custom_id=f"follow_up_{i}")
            button.callback = self.button_callback
            self.add_item(button)

    async def on_timeout(self):
        for item in self.children:
            if isinstance(item, discord.ui.Button): item.disabled = True
        try: await self.original_message.edit(view=None)
        except discord.NotFound: pass
        except discord.Forbidden: pass
        except Exception as e: print(f"ãƒœã‚¿ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç·¨é›†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    async def interaction_check(self, interaction: discord.Interaction) -> bool:
        return True # èª°ã§ã‚‚æŠ¼ã›ã‚‹

    async def button_callback(self, interaction: discord.Interaction):
        """ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã®å‡¦ç† (LLMå‘¼ã³å‡ºã—ã‚’æŠ½è±¡åŒ–)"""
        if not llm_handler: # LLMæœªåˆæœŸåŒ–
            await interaction.response.send_message(bot_constants.ERROR_MSG_INTERNAL + " (LLM Handler)", ephemeral=True)
            return
        await interaction.response.defer()

        button_label = ""
        custom_id = interaction.data.get("custom_id", "")
        if custom_id.startswith("follow_up_"):
            try:
                index = int(custom_id.split("_")[-1])
                if 0 <= index < len(self.follow_up_prompts): button_label = self.follow_up_prompts[index]
            except (ValueError, IndexError): pass

        if not button_label:
            await interaction.followup.send(bot_constants.ERROR_MSG_BUTTON_ERROR, ephemeral=True)
            return

        print(f"è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³æŠ¼ä¸‹: '{button_label}' by {interaction.user.display_name}")

        channel_id = interaction.channel_id
        if not channel_id or not interaction.channel:
            await interaction.followup.send(bot_constants.ERROR_MSG_CHANNEL_ERROR, ephemeral=True)
            return

        # å…ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–
        for item in self.children:
            if isinstance(item, discord.ui.Button): item.disabled = True
        try: await interaction.edit_original_response(view=self)
        except discord.NotFound: pass
        except discord.Forbidden: pass
        except Exception as e: print(f"è¿½è·¡è³ªå•å¿œç­”å‰ã®ãƒœã‚¿ãƒ³ç„¡åŠ¹åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

        # --- å¿œç­”ç”Ÿæˆå‡¦ç† ---
        async with interaction.channel.typing():
            chat_history = await load_cache(channel_id)
            deep_cache_summary = await load_deep_cache(channel_id)
            user_entry_parts = [{'text': button_label}]

            used_model_name, response_text = await llm_handler.generate_response(
                content_parts=user_entry_parts,
                chat_history=chat_history,
                deep_cache_summary=deep_cache_summary
            )

            sent_followup_message = None
            if response_text:
                is_error_response = llm_handler._is_error_message(response_text)

                response_chunks = [response_text[i:i+1990] for i in range(0, len(response_text), 1990)]
                first_chunk = True
                for chunk in response_chunks:
                    if first_chunk:
                        sent_followup_message = await interaction.followup.send(chunk)
                        first_chunk = False
                    else:
                        await interaction.channel.send(chunk)

                if not is_error_response:
                    current_history = chat_history + [{'role': 'user', 'parts': user_entry_parts}]
                    current_history.append({'role': 'model', 'parts': [{'text': response_text}]})
                    await save_cache(channel_id, current_history)

                    if sent_followup_message:
                        await generate_and_add_followup_buttons(sent_followup_message, channel_id)
                    else:
                         print("è­¦å‘Š: ãƒœã‚¿ãƒ³å¿œç­”å¾Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—å¤±æ•—ã€é€£ç¶šãƒœã‚¿ãƒ³ç”Ÿæˆã‚¹ã‚­ãƒƒãƒ—ã€‚")
            else:
                await interaction.followup.send(llm_handler.format_error_message(bot_constants.ERROR_TYPE_UNKNOWN, "Empty response received."))


# --- Discord BOT è¨­å®š ---
intents = discord.Intents.default()
intents.message_content = True
intents.members = True
intents.guilds = True
intents.reactions = True

client = discord.Client(intents=intents)

# --- ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© ---
@client.event
async def on_ready():
    global discord_client_id, llm_handler
    if client.user:
        discord_client_id = str(client.user.id)
        print(f"Client ID è¨­å®š: {discord_client_id}")
    else:
        print("CRITICAL: Botãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        await client.close(); return

    if not await initialize_llm_provider():
         print("CRITICAL: LLM Provider ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚Botã‚’çµ‚äº†ã—ã¾ã™ã€‚")
         await client.close(); return

    if not DISCORD_TOKEN:
        print("CRITICAL: DISCORD_TOKEN ãŒ .env ã«æœªè¨­å®šã€‚")
        await client.close(); return

    for cache_dir in [CACHE_DIR, DEEP_CACHE_DIR]:
        if not os.path.exists(cache_dir):
            try: os.makedirs(cache_dir); print(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{cache_dir}' ä½œæˆã€‚")
            except Exception as e: print(f"è­¦å‘Š: '{cache_dir}' ä½œæˆå¤±æ•—: {e}")

    print('--------------------------------------------------')
    print("æ¥ç¶šç¢ºèªã€‚â€¦å‘½ä»¤å¾…æ©Ÿä¸­ã€‚ãªã«ã‹å¾¡ç”¨ã§ã—ã‚‡ã†ã‹ã€‚")
    print(f'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ {client.user} ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã€‚')
    print(f'ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {LLM_PROVIDER_NAME}')
    if llm_handler:
        primary_name = llm_handler.get_model_name('primary') or "N/A"
        secondary_name = llm_handler.get_model_name('secondary') or "N/A"
        lowload_name = llm_handler.get_model_name('lowload') or "N/A"
        print(f'ãƒ¢ãƒ‡ãƒ«è¨­å®š: Primary={primary_name}, Secondary={secondary_name}, Lowload={lowload_name}')
    if API_BASE_URL_FOR_PROVIDER: print(f'API Base URL: {API_BASE_URL_FOR_PROVIDER}')
    print('--------------------------------------------------')

    activity_text = f"å‘½ä»¤å¾…æ©Ÿä¸­ ({LLM_PROVIDER_NAME}) | !poll, !timer, !csum, !cclear"
    if llm_handler and (llm_handler.get_model_name('lowload') is None or llm_handler.get_model_name('lowload') == ""):
         activity_text += " (ä¸€éƒ¨æ©Ÿèƒ½åˆ¶é™)"
    await client.change_presence(activity=discord.Game(name=activity_text))

    print("Bot is ready!")


@client.event
async def on_message(message: discord.Message):
    if message.author == client.user: return
    if not message.guild: return
    if not llm_handler:
        print("Warning: LLM Handler not initialized. Skipping message processing.")
        return

    if message.content:
        content_lower = message.content.lower()

        # --- ã‚³ãƒãƒ³ãƒ‰å‡¦ç† ---
        if content_lower == '!csum':
            async with message.channel.typing():
                success, response_msg = await summarize_deep_cache(message.channel.id)
                await message.reply(response_msg, mention_author=False)
            return
        elif content_lower == '!cclear':
            async with message.channel.typing():
                channel_id = message.channel.id
                print(f"Deep Cache ã‚¯ãƒªã‚¢å®Ÿè¡Œ (!cclear, Channel: {channel_id})...")
                await save_deep_cache(channel_id, None)
                print(f"Deep Cache ã‚¯ãƒªã‚¢å®Œäº† (Channel: {channel_id})ã€‚")
                await message.reply("é•·æœŸè¨˜æ†¶(Deep Cache)ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚", mention_author=False)
            return
        elif content_lower.startswith('!timer '):
            match = re.match(r'!timer\s+(\d+)\s*(åˆ†|åˆ†å¾Œ|minute|minutes)\s*(.*)', message.content, re.IGNORECASE)
            if match:
                minutes = int(match.group(1))
                timer_prompt = match.group(3).strip()
                if not timer_prompt: await message.reply(bot_constants.ERROR_MSG_TIMER_INVALID + " å†…å®¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚", mention_author=False); return
                if minutes <= 0: await message.reply(bot_constants.ERROR_MSG_TIMER_INVALID + " æ™‚é–“ã¯1åˆ†ä»¥ä¸Šã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚", mention_author=False); return
                await message.channel.send(f"{minutes}åˆ†å¾Œã«ã‚¿ã‚¤ãƒãƒ¼ã‚’è¨­å®šã—ã¾ã—ãŸã€‚ å†…å®¹: ã€Œ{timer_prompt}ã€")
                print(f"ã‚¿ã‚¤ãƒãƒ¼è¨­å®š: {minutes}åˆ†å¾Œ, {timer_prompt}, Ch: {message.channel.name}")
                asyncio.create_task(execute_timer(message.channel, minutes, timer_prompt, message.author))
            else: await message.reply(bot_constants.ERROR_MSG_TIMER_INVALID + " ä¾‹: `!timer 10åˆ† ä½œæ¥­çµ‚äº†`", mention_author=False)
            return
        elif content_lower.startswith('!poll '):
            args = message.content.split(' ', 1)
            if len(args) < 2 or not args[1].strip(): await message.reply(bot_constants.ERROR_MSG_POLL_INVALID + " å†…å®¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚", mention_author=False); return
            poll_content = args[1].strip(); parts = poll_content.split('"'); options = []
            if len(parts) >= 3 and parts[0] == '': question = parts[1].strip(); options_str = parts[2].strip(); options = [opt.strip() for opt in options_str.split() if opt.strip()]
            else: temp_parts = poll_content.split(' ', 1); question = temp_parts[0].strip();
            if len(temp_parts) > 1: options_str = temp_parts[1].strip(); options = [opt.strip() for opt in options_str.split() if opt.strip()]
            if not question or len(options) < 2 or len(options) > 10: await message.reply(bot_constants.ERROR_MSG_POLL_INVALID, mention_author=False); return
            async with message.channel.typing():
                embed = discord.Embed(title=f"æŠ•ç¥¨: {question}", description="ä»¥ä¸‹ã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„ã€‚", color=discord.Color.blue())
                option_emojis = ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£', '5ï¸âƒ£', '6ï¸âƒ£', '7ï¸âƒ£', '8ï¸âƒ£', '9ï¸âƒ£', 'ğŸ”Ÿ']
                options_text = "".join(f"{option_emojis[i]} {option}\n" for i, option in enumerate(options))
                embed.add_field(name="é¸æŠè‚¢", value=options_text, inline=False); embed.set_footer(text=f"ä½œæˆè€…: {message.author.display_name}")
                try: poll_message = await message.channel.send(embed=embed); [await poll_message.add_reaction(option_emojis[i]) for i in range(len(options))]; print(f"æŠ•ç¥¨ä½œæˆ: {question}")
                except discord.Forbidden: await message.channel.send(bot_constants.ERROR_MSG_PERMISSION_DENIED + " (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡/ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ )")
                except Exception as e: print(f"æŠ•ç¥¨ä½œæˆã‚¨ãƒ©ãƒ¼: {e}"); await message.channel.send(bot_constants.ERROR_MSG_INTERNAL + " æŠ•ç¥¨ä½œæˆå¤±æ•—ã€‚")
            return

    # --- ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å¿œç­” (LLMå‘¼ã³å‡ºã—ã‚’æŠ½è±¡åŒ–) ---
    if client.user and client.user.mentioned_in(message):
        async with message.channel.typing():
            channel_id = message.channel.id

            # 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™
            mention_strings = [f'<@!{client.user.id}>', f'<@{client.user.id}>']
            text_content = message.content if message.content else ""
            for mention in mention_strings: text_content = text_content.replace(mention, '')
            text_content = text_content.strip()
            use_channel_history = '!his' in text_content
            if use_channel_history: text_content = text_content.replace('!his', '').strip(); print("å±¥æ­´å‚ç…§ãƒ•ãƒ©ã‚° (!his) æ¤œå‡ºã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡è¦–ã€‚")

            request_parts: List[Dict[str, Any]] = []
            if text_content: request_parts.append({'text': text_content})
            attached_files_data_for_cache = []
            file_error_occurred_once = False
            if message.attachments:
                print(f"{len(message.attachments)}å€‹ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã€‚")
                max_images = 5; image_count = 0
                for attachment in message.attachments:
                    if attachment.size > 50 * 1024 * 1024:
                        if not file_error_occurred_once: await message.channel.send(bot_constants.ERROR_MSG_FILE_SIZE_LIMIT); file_error_occurred_once = True; print(f"è­¦å‘Š: æ·»ä»˜ '{attachment.filename}' ã‚µã‚¤ã‚ºè¶…éã€‚")
                        continue
                    if attachment.content_type and attachment.content_type.startswith("image/"):
                        image_count += 1
                        if image_count > max_images:
                            if not file_error_occurred_once: await message.channel.send(bot_constants.ERROR_MSG_MAX_IMAGE_SIZE); file_error_occurred_once = True; print(f"è­¦å‘Š: ç”»åƒæ•°è¶…éã€‚")
                            continue
                    try:
                        file_bytes = await attachment.read()
                        mime_type = attachment.content_type
                        if mime_type is None: mime_type, _ = mimetypes.guess_type(attachment.filename); mime_type = mime_type or 'application/octet-stream'
                        if mime_type and mime_type.startswith('text/plain'): mime_type = 'text/plain'

                        supported_prefixes = ('image/', 'text/')
                        if not any(mime_type.startswith(prefix) for prefix in supported_prefixes):
                             print(f"è­¦å‘Š: æœªå¯¾å¿œMIME '{mime_type}' ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                             if not file_error_occurred_once: await message.channel.send(f"{bot_constants.ERROR_MSG_ATTACHMENT_UNSUPPORTED} ({mime_type})"); file_error_occurred_once = True
                             continue

                        request_parts.append({'inline_data': {'mime_type': mime_type, 'data': file_bytes}})
                        attached_files_data_for_cache.append({'mime_type': mime_type, 'data': file_bytes})
                        print(f"æ·»ä»˜ '{attachment.filename}' ({mime_type}) è¿½åŠ ã€‚")
                    except discord.HTTPException as e:
                        if not file_error_occurred_once: await message.channel.send(f"{bot_constants.ERROR_MSG_IMAGE_READ_FAIL} (Discord Error)"); file_error_occurred_once = True; print(f"ã‚¨ãƒ©ãƒ¼: æ·»ä»˜ '{attachment.filename}' èª­è¾¼å¤±æ•— (Discord): {e}")
                    except Exception as e:
                        if not file_error_occurred_once: await message.channel.send(f"{bot_constants.ERROR_MSG_INTERNAL} (ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼)"); file_error_occurred_once = True; print(f"ã‚¨ãƒ©ãƒ¼: æ·»ä»˜ '{attachment.filename}' å‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼: {e}")

            if not request_parts: print("å¿œç­”å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆ/æ·»ä»˜ãªã—ã€ã‚¹ã‚­ãƒƒãƒ—ã€‚"); return

            # 2. å±¥æ­´ã®æº–å‚™
            chat_history: List[Dict[str, Any]] = []
            if use_channel_history:
                print(f"ãƒãƒ£ãƒ³ãƒãƒ«å±¥æ­´ ({HISTORY_LIMIT}ä»¶) å–å¾—ä¸­...")
                try:
                    history_messages = [msg async for msg in message.channel.history(limit=HISTORY_LIMIT + 1)]
                    history_messages.reverse(); history_messages = history_messages[:-1]
                    for msg in history_messages:
                        role = 'model' if msg.author == client.user else 'user'
                        msg_parts = []; txt = msg.content or ""
                        if msg.attachments: txt += " " + " ".join([f"[{att.filename} æ·»ä»˜]" for att in msg.attachments])
                        if txt: msg_parts.append({'text': txt.strip()})
                        if msg_parts: chat_history.append({'role': role, 'parts': msg_parts})
                    print(f"ãƒãƒ£ãƒ³ãƒãƒ«å±¥æ­´ã‹ã‚‰ {len(chat_history)} ä»¶æ•´å½¢ã€‚")
                except discord.Forbidden: await message.channel.send(bot_constants.ERROR_MSG_PERMISSION_DENIED + " (å±¥æ­´èª­å–)"); return
                except Exception as e: await message.channel.send(bot_constants.ERROR_MSG_HISTORY_READ_FAIL); print(f"ã‚¨ãƒ©ãƒ¼: å±¥æ­´å–å¾—å¤±æ•—: {e}"); return
            else:
                print(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id} ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­è¾¼ä¸­...")
                chat_history = await load_cache(channel_id)
                print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ {len(chat_history)} ä»¶èª­è¾¼ã€‚")

            # 3. Deep Cacheã®æº–å‚™
            deep_cache_summary = await load_deep_cache(channel_id)
            if deep_cache_summary: print("Deep Cacheæƒ…å ±èª­è¾¼ã€‚")
            else: print("Deep Cacheæƒ…å ±ãªã—ã€‚")

            # 4. LLM APIå‘¼ã³å‡ºã— (æŠ½è±¡åŒ–)
            # generate_response ã¯å†…éƒ¨ã§é©åˆ‡ãªãƒ¢ãƒ‡ãƒ«åã‚’ä½¿ã£ã¦å¤‰æ›ã‚’è¡Œã†
            used_model_name, response_text = await llm_handler.generate_response(
                content_parts=request_parts,
                chat_history=chat_history,
                deep_cache_summary=deep_cache_summary
            )

            # 5. å¿œç­”é€ä¿¡
            sent_message = None
            if response_text:
                is_error_response_text = llm_handler._is_error_message(response_text) # ã‚¨ãƒ©ãƒ¼åˆ¤å®šç”¨

                if not is_error_response_text: # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ãªã„å ´åˆã®ã¿åˆ†å‰²é€ä¿¡
                    response_chunks = [response_text[i:i+1990] for i in range(0, len(response_text), 1990)]
                    first_chunk = True
                    for chunk in response_chunks:
                        if first_chunk: sent_message = await message.reply(chunk, mention_author=False); first_chunk = False
                        else: await message.channel.send(chunk)
                else:
                    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã¯ãã®ã¾ã¾é€ä¿¡
                    await message.reply(response_text, mention_author=False)


            # 6. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
            # ã‚¨ãƒ©ãƒ¼åˆ¤å®šã¯ LLM Provider ãŒè¿”ã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åŸºã¥ã„ã¦è¡Œã†
            is_error_response = response_text is None or llm_handler._is_error_message(response_text)

            if not is_error_response and not use_channel_history:
                user_entry_parts = []
                if text_content: user_entry_parts.append({'text': text_content})
                user_entry_parts.extend({'inline_data': file_info} for file_info in attached_files_data_for_cache)
                if user_entry_parts:
                     current_history = chat_history + [{'role': 'user', 'parts': user_entry_parts}]
                     # ãƒ¢ãƒ‡ãƒ«å¿œç­”ã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (ç”»åƒå¿œç­”ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãªã„)
                     if response_text and not llm_handler._is_error_message(response_text):
                         current_history.append({'role': 'model', 'parts': [{'text': response_text}]})
                     await save_cache(channel_id, current_history)


            # 7. è¿½è·¡è³ªå•ãƒœã‚¿ãƒ³ç”Ÿæˆ
            if sent_message and not is_error_response:
                 await generate_and_add_followup_buttons(sent_message, channel_id)


# --- ã‚¿ã‚¤ãƒãƒ¼å®Ÿè¡Œé–¢æ•° (LLMå‘¼ã³å‡ºã—ã‚’æŠ½è±¡åŒ–) ---
async def execute_timer(channel: discord.TextChannel, minutes: int, prompt: str, author: discord.User):
    if not llm_handler: return # LLMæœªåˆæœŸåŒ–
    await asyncio.sleep(minutes * 60)
    print(f"ã‚¿ã‚¤ãƒãƒ¼å®Ÿè¡Œ: {minutes}åˆ†çµŒé, {prompt}, Ch: {channel.name}")
    async with channel.typing():
        mention = author.mention
        base_message = f"{mention} æŒ‡å®šæ™‚åˆ»ã§ã™ã€‚ã‚¿ã‚¤ãƒãƒ¼ã®å†…å®¹: ã€Œ{prompt}ã€"

        timer_execution_prompt = f"ã€Œ{prompt}ã€ã¨ã„ã†ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼ã®æŒ‡å®šæ™‚åˆ»ã«ãªã‚Šã¾ã—ãŸã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ ({author.display_name}) ã«å‘ã‘ã¦ã€ç°¡æ½”ãªè£œè¶³ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        _used_model, response_text = await llm_handler.generate_response([{'text': timer_execution_prompt}], chat_history=None, deep_cache_summary=None)

        full_message = base_message
        if response_text and not llm_handler._is_error_message(response_text):
            full_message += f"\n\n{response_text}"
        elif response_text:
             full_message += f"\n\nè£œè¶³æƒ…å ±ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚({response_text})"

        for i in range(0, len(full_message), 1990): await channel.send(full_message[i:i+1990])


# --- BOTèµ·å‹• ---
if __name__ == "__main__":
    try:
        import aiofiles
        import dotenv
        if LLM_PROVIDER_NAME == 'GEMINI':
            import google.generativeai
        elif LLM_PROVIDER_NAME == 'MISTRAL':
             import openai
        else:
             print(f"è­¦å‘Š: æœªå¯¾å¿œã®LLM_PROVIDER '{LLM_PROVIDER_NAME}' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚")
             pass

    except ImportError as e:
        print(f"CRITICAL: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
        print("å®Ÿè¡Œå‰ã« `pip install aiofiles python-dotenv discord.py google-generativeai openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        exit(1)
    except Exception as e:
         print(f"CRITICAL: ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
         exit(1)

    try:
        print("BOTèµ·å‹•å‡¦ç†é–‹å§‹...")
        client.run(DISCORD_TOKEN)
    except discord.LoginFailure: print("CRITICAL: ä¸æ­£ãªDiscordãƒˆãƒ¼ã‚¯ãƒ³ã€‚")
    except discord.PrivilegedIntentsRequired: print("CRITICAL: ç‰¹æ¨©ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆ(Message Contentç­‰)ç„¡åŠ¹ã€‚Discord Developer Portalç¢ºèªè¦ã€‚")
    except Exception as e:
        print(f"CRITICAL: BOTå®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback; traceback.print_exc()